

```{r}
rm(list = ls())
```

```{r}
library(plyr)
library(dplyr)
library(lubridate)
library(tidyr)
library(tibble)
library(lmtest)
library(stats)
library(parallel)
library(foreach)
library(doParallel)
library(purrr)
library(logging)
```



```{r}
library(readr)
#data <- read_csv("London_Marylebone_Roadside_MET_fillna.csv", col_types = cols(
#  date = col_datetime(format = "%Y-%m-%d %H:%M:%S")
#))
data_prepared <- read_csv("data_prepared_random.csv", col_types = cols(
  date = col_datetime(format = "%Y-%m-%d %H:%M:%S")
))
```


```{r}
library(h2o)
```


```{r}
#folder_path <- "C:\\Users\\Song\\Desktop\\normet\\R"
folder_path <- "/Users/user/The University of Manchester Dropbox/Congbo Song/normet/R"
files <- list.files(path = folder_path, pattern = "\\.r$")

# 方法二：指定文件夹路径
for (file in files) {
  source(file.path(folder_path, file))
}

```




```{r}
df1a <- nm_prepare_data(data_prepared, value='value',feature_names=c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'), split_method='random',  fraction=0.75, seed=7654321)
```

```{r}
# 假设你的数据框名称是 df
df1b <- head(df1a, 1000)

```




```{r}
model_config<- list(
  max_models = 10,
  max_mem_size = '16g'
)
automl <- nm_train_model(df1b, variables = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), model_config = model_config)
```
```{r}
df1b$value_predictx <- nm_predict(automl@leader,df1b)
```



```{r}
nm_modStats(df1b, automl@leader)
```




```{r}
# Initialize H2O
start_time <- Sys.time()
#loaded_model <- load_h2o_model(automl)
df1bdew <- nm_normalise(df1b, model = automl@leader, feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables_resample = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'),aggregate=TRUE) 
end_time <- Sys.time()
execution_time <- end_time - start_time
print(execution_time)
```



```{r}
#loaded_model <- load_h2o_model(automl)
dfdoall <- nm_do_all(df1b,model = automl@leader,feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables_resample = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'))


```



```{r}
dfdoall1 <- nm_do_all(df1b,value='value', feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables_resample = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'),seed=254)
```



```{r}
doallunc <-nm_do_all_unc(df1b,value='value',feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables_resample = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'),n_samples=100,n_models=5)
```
```{r}


```




```{r}

dfrolling <- nm_rolling_dew(df1b, model = automl@leader, value='value', feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables_resample = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp'), n_samples=100,window_days=14, rollingevery=7)
```

```{r}
```

```{r}
df1b <- head(df1a, 2000)
dfrollingmet <- nm_rolling_met(df1b, model = automl@leader,feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), n_samples=100,window_days=14,rollingevery=7)
```

```{r}

```

```{r}
dfdeemi <- nm_decom_emi(df1b, model = automl@leader,feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), n_samples=300)
```

```{r}
dfdeemi <- nm_decom_met(df1b, model = automl@leader,feature_names = c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), n_samples=100)
```


```{r}


# library(pdp)
# library(dplyr)
# library(parallel)
# library(doParallel)

# library(pdp)
# library(dplyr)
# library(parallel)
# library(doParallel)

nm_pdp <- function(df, model, feature_names, variables = NULL, training_only = TRUE, grid.resolution = 20, n_cores = NULL) {
  if (is.null(variables)) {
    variables <- feature_names
  }

  if (training_only) {
    df <- df[df$set == "training", ]
  }

  X_train <- df[, feature_names, drop = FALSE]

  if (is.null(n_cores)) {
    n_cores <- detectCores() - 1
  }

  cl <- makeCluster(n_cores)
  registerDoParallel(cl)

  results <- foreach(var = variables, .packages = c('pdp', 'h2o'), .export = c("nm_pdp_worker", "nm_predict","initialize_h2o")) %dopar% {
    initialize_h2o()
    nm_pdp_worker(model, X_train, var, grid.resolution)
  }

  stopCluster(cl)

  df_predict <- bind_rows(results)
  return(df_predict)
}


nm_pdp_worker <- function(model, df, variable, grid.resolution) {
  initialize_h2o()
  pd_results <- partial(object = model, pred.var = variable, train = df, pred.fun = nm_predict, grid.resolution = grid.resolution)
  pd_results$var <- variable
  
  df_predict <- data.frame(
    var = variable,
    id = pd_results$yhat.id,
    var_value = pd_results[[variable]],        
    pdp_value = pd_results$yhat    
  )

  return(df_predict)
}

```





```{r}
all_features=c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour')
pdp_values <-nm_pdp(df1b,automl@leader,  feature_names =  c('ws', 'wd', 'air_temp', 'tcc','blh', 'atmos_pres', 'ssrd', 'RH', 'tp', 'date_unix','day_julian','weekday','hour'), variables = c('ws','blh'))
```

```{r}
library(readxl)
df <- read_excel('AQ_Weekly.xlsx')
```

```{r}

df <- df %>%
  filter(date >= as.Date('2015-05-01') & date < as.Date('2016-04-30'))
control_pool=c("Dongguan", "Zhongshan" , "Foshan", "Beihai"
               , "Nanning","Nanchang" , "Xiamen", "Taizhou"
               , "Ningbo","Guangzhou" , "Huizhou", "Hangzhou"
               , "Liuzhou", "Shantou", "Jiangmen", "Heyuan", "Quanzhou","Haikou" , "Shenzhen", "Wenzhou", "Huzhou"
               , "Zhuhai", "Fuzhou", "Shaoxing", "Zhaoqing","Zhoushan"
               , "Quzhou", "Jinhua", "Shaoguan" , "Sanya"
               , "Jieyang" , "Meizhou", "Shanwei"
               , "Zhanjiang" , "Chaozhou", "Maoming" , "Yangjiang")

df <- df %>%
  filter(ID %in% c(control_pool, "2+26 cities"))

df <- df %>%
  mutate(after_treatment = date > as.Date('2015-10-23'))
```

```{r}
poll_col='SO2wn' 
date_col='date'
code_col='ID'
treat_target='2+26 cities'
post_col='after_treatment'

```



```{r}

```


```{r}
dfsc=nm_scm(df,'SO2wn','date','ID',"2+26 cities",control_pool,'after_treatment')
```

```{r}
xy=nm_scm_parallel(df,'SO2wn','date','ID',control_pool,'after_treatment')
```


```{r}
cutoff_date <- '2015-10-23'
training_split <- 0.75
treat_target <- '2+26 cities'
control_pool=c("Dongguan", "Zhongshan" , "Foshan", "Beihai"
               , "Nanning","Nanchang" , "Xiamen", "Taizhou"
               , "Ningbo","Guangzhou" , "Huizhou", "Hangzhou"
               , "Liuzhou", "Shantou", "Jiangmen", "Heyuan", "Quanzhou","Haikou" , "Shenzhen", "Wenzhou", "Huzhou"
               , "Zhuhai", "Fuzhou", "Shaoxing", "Zhaoqing","Zhoushan"
               , "Quzhou", "Jinhua", "Shaoguan" , "Sanya"
               , "Jieyang" , "Meizhou", "Shanwei"
               , "Zhanjiang" , "Chaozhou", "Maoming" , "Yangjiang")
model_config <- list(
  nfolds = 10,
  max_models = 20
)


```

```{r}
mlsc=nm_mlsc(df,'SO2wn','date','ID',"2+26 cities",control_pool,'2015-10-23', model_config, training_split = 0.8)
```

```{r}
nm_mlsc_parallel <- function(df, poll_col, date_col, code_col, control_pool, cutoff_date, model_config, training_split = 0.75, n_cores = NULL) {

  # Check if h2o is already initialized
  initialize_h2o(n_cores)

  treatment_pool <- unique(df[[code_col]])

  df_synthetic_list <- list()
  mod_stats_list <- list()
  models_list <- list()

  # Determine number of CPU cores to use
  n_cores <- ifelse(is.null(n_cores), parallel::detectCores() - 1, n_cores)

  start_time <- Sys.time()

  # Initialize the progress bar
  pb <- progress_bar$new(
    format = "  Treatment :current/:total [:bar] :percent :elapsedfull ETA: :eta",
    total = length(treatment_pool),
    clear = FALSE,
    width = 80
  )

  for (i in seq_along(treatment_pool)) {
    code <- treatment_pool[i]
    success <- FALSE

    while (!success) {
      tryCatch({
        res <- nm_mlsc(df, poll_col, date_col, code_col, code, control_pool, cutoff_date, model_config, training_split)

        synthetic_data <- res[[1]]
        mod_stats_data <- res[[2]]
        model_data <- res[[3]]

        df_synthetic_list[[i]] <- synthetic_data
        mod_stats_list[[i]] <- mod_stats_data
        models_list[[i]] <- model_data

        success <- TRUE
      }, error = function(e) {
        if (grepl("H2O connection error", e$message)) {
          cat(sprintf("%s: H2O connection lost during treatment %d/%d: %s. Reinitializing H2O...\n", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), i, length(treatment_pool), e$message))
          initialize_h2o(n_cores)
        } else {
          cat(sprintf("%s: Error during treatment %d/%d: %s\n", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), i, length(treatment_pool), e$message))
          Sys.sleep(10)  # Wait for 10 seconds before retrying
        }
      })
    }

    if (success) {
      pb$tick()
    }
  }

  synthetic_all <- bind_rows(df_synthetic_list)
  mod_stats_all <- bind_rows(mod_stats_list)
  models_all <- models_list

  # Shutdown H2O after use
  # h2o.shutdown(prompt = FALSE)
  # loginfo('H2O shutdown complete')

  return(list(synthetic_all = synthetic_all, mod_stats_all = mod_stats_all, models_all = models_all))
}


```


```{r}
model_config <- list(
  nfolds = 5,
  max_models = 5
)

library(progress)
nmpara <- nm_mlsc_parallel(df,poll_col='SO2wn',date_col='date',code_col='ID', control_pool,cutoff_date='2015-10-23', model_config, training_split = 0.9)
```



