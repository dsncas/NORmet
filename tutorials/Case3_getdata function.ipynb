{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fdb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2602bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import normet.getdata as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e29c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 13:03:33,928 INFO Welcome to the CDS\n",
      "2023-09-12 13:03:33,935 INFO Welcome to the CDS\n",
      "2023-09-12 13:03:33,939 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 13:03:33,936 INFO Welcome to the CDS\n",
      "2023-09-12 13:03:33,951 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 13:03:33,935 INFO Welcome to the CDS\n",
      "2023-09-12 13:03:33,938 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 13:03:33,959 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 13:03:34,014 INFO Request is queued\n",
      "2023-09-12 13:03:34,034 INFO Request is queued\n",
      "2023-09-12 13:03:34,058 INFO Request is queued\n",
      "2023-09-12 13:03:34,059 INFO Request is queued\n",
      "2023-09-12 13:03:35,093 INFO Request is running\n",
      "2023-09-12 13:07:52,666 INFO Request is running\n",
      "2023-09-12 13:07:52,681 INFO Request is completed\n",
      "2023-09-12 13:07:52,683 INFO Downloading https://download-0001-clone.copernicus-climate.eu/cache-compute-0001/cache/data9/adaptor.mars.internal-1694520391.3694432-14236-4-58d82960-2994-459d-b1c0-fda2385d57c5.nc to ./normet/datasets/ERA5_netcdf/era5_data_43.0_-103.0.nc (149.3K)\n",
      "2023-09-12 13:07:53,148 INFO Download rate 321.7K/s                             \n",
      "2023-09-12 13:11:53,280 INFO Request is completed\n",
      "2023-09-12 13:11:53,284 INFO Downloading https://download-0000-clone.copernicus-climate.eu/cache-compute-0000/cache/data2/adaptor.mars.internal-1694520589.0602365-29266-2-b843e5eb-5081-4492-9d08-0a8e38be9829.nc to ./normet/datasets/ERA5_netcdf/era5_data_41.0_-101.0.nc (149.3K)\n",
      "2023-09-12 13:11:53,301 INFO Request is running\n",
      "2023-09-12 13:11:53,778 INFO Download rate 303.6K/s                             \n",
      "2023-09-12 13:13:53,609 INFO Request is completed\n",
      "2023-09-12 13:13:53,611 INFO Request is running\n",
      "2023-09-12 13:13:53,618 INFO Downloading https://download-0019.copernicus-climate.eu/cache-compute-0019/cache/data8/adaptor.mars.internal-1694520747.1054761-31616-12-7cec702d-e0f3-46f7-b6ae-e3c4db6993d3.nc to ./normet/datasets/ERA5_netcdf/era5_data_40.0_-100.0.nc (149.3K)\n",
      "2023-09-12 13:13:54,122 INFO Download rate 299.1K/s                             \n",
      "2023-09-12 13:15:54,049 INFO Request is completed\n",
      "2023-09-12 13:15:54,053 INFO Downloading https://download-0002-clone.copernicus-climate.eu/cache-compute-0002/cache/data1/adaptor.mars.internal-1694520926.732925-19341-17-1c76c6fb-e5a7-43a8-9ca0-026e6bb2c0a1.nc to ./normet/datasets/ERA5_netcdf/era5_data_42.0_-102.0.nc (149.3K)\n",
      "2023-09-12 13:15:55,491 INFO Download rate 104K/s                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Thread(Thread-8 (download_era5_worker), stopped 13138083840)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.download_era5(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],\n",
    "              year_range = [ '2023'],month_range = ['08','09'],\n",
    "              path=r'./normet/datasets/ERA5_netcdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79179811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=gd.era5_dataframe(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],path=r'./normet/datasets/ERA5_netcdf/',n_cores=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eccb18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>blh</th>\n",
       "      <th>sp</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <td>-3.738438</td>\n",
       "      <td>-1.559481</td>\n",
       "      <td>293.021454</td>\n",
       "      <td>304.917114</td>\n",
       "      <td>1102.908569</td>\n",
       "      <td>93218.492188</td>\n",
       "      <td>1.368530e+06</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 01:00:00</th>\n",
       "      <td>-3.776691</td>\n",
       "      <td>-1.448858</td>\n",
       "      <td>293.048889</td>\n",
       "      <td>304.282867</td>\n",
       "      <td>929.300903</td>\n",
       "      <td>93237.273438</td>\n",
       "      <td>6.759171e+05</td>\n",
       "      <td>0.124334</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 02:00:00</th>\n",
       "      <td>-4.739495</td>\n",
       "      <td>-1.033687</td>\n",
       "      <td>293.317291</td>\n",
       "      <td>301.812561</td>\n",
       "      <td>791.139465</td>\n",
       "      <td>93295.148438</td>\n",
       "      <td>1.279141e+05</td>\n",
       "      <td>0.736759</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 03:00:00</th>\n",
       "      <td>-4.741343</td>\n",
       "      <td>-0.801298</td>\n",
       "      <td>293.047455</td>\n",
       "      <td>298.375427</td>\n",
       "      <td>638.904541</td>\n",
       "      <td>93401.437500</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 04:00:00</th>\n",
       "      <td>-4.164585</td>\n",
       "      <td>-0.694653</td>\n",
       "      <td>293.413971</td>\n",
       "      <td>297.781311</td>\n",
       "      <td>512.873535</td>\n",
       "      <td>93434.648438</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 08:00:00</th>\n",
       "      <td>-1.062305</td>\n",
       "      <td>4.146491</td>\n",
       "      <td>282.146606</td>\n",
       "      <td>289.248993</td>\n",
       "      <td>377.380371</td>\n",
       "      <td>89543.390625</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>-2.328306e-10</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 09:00:00</th>\n",
       "      <td>-0.711289</td>\n",
       "      <td>4.322321</td>\n",
       "      <td>281.472076</td>\n",
       "      <td>289.097961</td>\n",
       "      <td>366.730591</td>\n",
       "      <td>89552.242188</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.161934</td>\n",
       "      <td>-2.328306e-10</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 10:00:00</th>\n",
       "      <td>0.429012</td>\n",
       "      <td>4.266153</td>\n",
       "      <td>280.505981</td>\n",
       "      <td>288.010193</td>\n",
       "      <td>237.444580</td>\n",
       "      <td>89488.187500</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.257931</td>\n",
       "      <td>-2.328306e-10</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 11:00:00</th>\n",
       "      <td>0.700046</td>\n",
       "      <td>3.944882</td>\n",
       "      <td>280.533325</td>\n",
       "      <td>288.211884</td>\n",
       "      <td>245.179199</td>\n",
       "      <td>89481.460938</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.084019</td>\n",
       "      <td>2.879184e-06</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 12:00:00</th>\n",
       "      <td>0.926953</td>\n",
       "      <td>3.571242</td>\n",
       "      <td>280.920380</td>\n",
       "      <td>288.552429</td>\n",
       "      <td>248.451538</td>\n",
       "      <td>89485.851562</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>-2.328306e-10</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3604 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          u10       v10         d2m         t2m          blh  \\\n",
       "2023-08-01 00:00:00 -3.738438 -1.559481  293.021454  304.917114  1102.908569   \n",
       "2023-08-01 01:00:00 -3.776691 -1.448858  293.048889  304.282867   929.300903   \n",
       "2023-08-01 02:00:00 -4.739495 -1.033687  293.317291  301.812561   791.139465   \n",
       "2023-08-01 03:00:00 -4.741343 -0.801298  293.047455  298.375427   638.904541   \n",
       "2023-08-01 04:00:00 -4.164585 -0.694653  293.413971  297.781311   512.873535   \n",
       "...                       ...       ...         ...         ...          ...   \n",
       "2023-09-07 08:00:00 -1.062305  4.146491  282.146606  289.248993   377.380371   \n",
       "2023-09-07 09:00:00 -0.711289  4.322321  281.472076  289.097961   366.730591   \n",
       "2023-09-07 10:00:00  0.429012  4.266153  280.505981  288.010193   237.444580   \n",
       "2023-09-07 11:00:00  0.700046  3.944882  280.533325  288.211884   245.179199   \n",
       "2023-09-07 12:00:00  0.926953  3.571242  280.920380  288.552429   248.451538   \n",
       "\n",
       "                               sp          ssrd       tcc            tp   lat  \\\n",
       "2023-08-01 00:00:00  93218.492188  1.368530e+06  0.189141  0.000000e+00  40.0   \n",
       "2023-08-01 01:00:00  93237.273438  6.759171e+05  0.124334  0.000000e+00  40.0   \n",
       "2023-08-01 02:00:00  93295.148438  1.279141e+05  0.736759  0.000000e+00  40.0   \n",
       "2023-08-01 03:00:00  93401.437500  1.250000e-01  0.995544  0.000000e+00  40.0   \n",
       "2023-08-01 04:00:00  93434.648438  1.250000e-01  1.000000  0.000000e+00  40.0   \n",
       "...                           ...           ...       ...           ...   ...   \n",
       "2023-09-07 08:00:00  89543.390625 -1.250000e-01  0.015229 -2.328306e-10  43.0   \n",
       "2023-09-07 09:00:00  89552.242188 -1.250000e-01  0.161934 -2.328306e-10  43.0   \n",
       "2023-09-07 10:00:00  89488.187500 -1.250000e-01  0.257931 -2.328306e-10  43.0   \n",
       "2023-09-07 11:00:00  89481.460938 -1.250000e-01  0.084019  2.879184e-06  43.0   \n",
       "2023-09-07 12:00:00  89485.851562 -1.250000e-01  0.021729 -2.328306e-10  43.0   \n",
       "\n",
       "                       lon  \n",
       "2023-08-01 00:00:00 -100.0  \n",
       "2023-08-01 01:00:00 -100.0  \n",
       "2023-08-01 02:00:00 -100.0  \n",
       "2023-08-01 03:00:00 -100.0  \n",
       "2023-08-01 04:00:00 -100.0  \n",
       "...                    ...  \n",
       "2023-09-07 08:00:00 -103.0  \n",
       "2023-09-07 09:00:00 -103.0  \n",
       "2023-09-07 10:00:00 -103.0  \n",
       "2023-09-07 11:00:00 -103.0  \n",
       "2023-09-07 12:00:00 -103.0  \n",
       "\n",
       "[3604 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a8f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 13:17:33,765 INFO Welcome to the CDS\n",
      "2023-09-12 13:17:33,768 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 13:17:33,862 INFO Request is queued\n",
      "2023-09-12 13:17:34,936 INFO Request is running\n",
      "2023-09-12 13:17:42,367 INFO Request is completed\n",
      "2023-09-12 13:17:42,371 INFO Downloading https://download-0021.copernicus-climate.eu/cache-compute-0021/cache/data7/adaptor.mars.internal-1694521059.1609402-22669-7-cf9d8a9c-b379-4d62-bde8-f1958d1bc671.nc to ./normet/datasets/ERA5_netcdf/era5_data_[40.0, 43.0]_[-103.0, -100.0].nc (56.8K)\n",
      "2023-09-12 13:17:42,890 INFO Download rate 110K/s                               \n"
     ]
    }
   ],
   "source": [
    "gd.download_era5_area(lat_lim = [40.0, 43.0],lon_lim = [-103.0,-100.0],\n",
    "              year_range = [ '2023'],month_range = [ '08', '09'],\n",
    "              day_range = ['01', '02', '03'],time_range = ['00:00', '01:00', '02:00'],path=r'./normet/datasets/ERA5_netcdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca9b01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>blh</th>\n",
       "      <th>sp</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <td>-3.738469</td>\n",
       "      <td>-1.559424</td>\n",
       "      <td>293.021576</td>\n",
       "      <td>304.916901</td>\n",
       "      <td>1102.932129</td>\n",
       "      <td>93218.429688</td>\n",
       "      <td>1.368522e+06</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 01:00:00</th>\n",
       "      <td>-3.776742</td>\n",
       "      <td>-1.448954</td>\n",
       "      <td>293.048981</td>\n",
       "      <td>304.282684</td>\n",
       "      <td>929.288391</td>\n",
       "      <td>93237.242188</td>\n",
       "      <td>6.759111e+05</td>\n",
       "      <td>0.124334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 02:00:00</th>\n",
       "      <td>-4.739501</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>293.317322</td>\n",
       "      <td>301.812622</td>\n",
       "      <td>791.130859</td>\n",
       "      <td>93295.015625</td>\n",
       "      <td>1.279279e+05</td>\n",
       "      <td>0.736759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-02 00:00:00</th>\n",
       "      <td>-3.386415</td>\n",
       "      <td>-2.400684</td>\n",
       "      <td>294.241333</td>\n",
       "      <td>306.335236</td>\n",
       "      <td>845.018921</td>\n",
       "      <td>93122.921875</td>\n",
       "      <td>1.121802e+06</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-02 01:00:00</th>\n",
       "      <td>-3.479061</td>\n",
       "      <td>-2.286000</td>\n",
       "      <td>294.416901</td>\n",
       "      <td>305.872009</td>\n",
       "      <td>700.480469</td>\n",
       "      <td>93119.210938</td>\n",
       "      <td>3.878394e+05</td>\n",
       "      <td>0.099370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-02 01:00:00</th>\n",
       "      <td>-1.653327</td>\n",
       "      <td>-1.693710</td>\n",
       "      <td>287.647888</td>\n",
       "      <td>305.156036</td>\n",
       "      <td>124.590942</td>\n",
       "      <td>89434.921875</td>\n",
       "      <td>4.045395e+05</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-02 02:00:00</th>\n",
       "      <td>-2.278763</td>\n",
       "      <td>-1.861523</td>\n",
       "      <td>287.411530</td>\n",
       "      <td>298.941101</td>\n",
       "      <td>81.365234</td>\n",
       "      <td>89471.640625</td>\n",
       "      <td>2.232738e+04</td>\n",
       "      <td>0.433720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 00:00:00</th>\n",
       "      <td>2.700427</td>\n",
       "      <td>0.106424</td>\n",
       "      <td>285.069061</td>\n",
       "      <td>307.079865</td>\n",
       "      <td>742.923950</td>\n",
       "      <td>89419.492188</td>\n",
       "      <td>7.392030e+05</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 01:00:00</th>\n",
       "      <td>2.448156</td>\n",
       "      <td>0.325350</td>\n",
       "      <td>283.627228</td>\n",
       "      <td>307.212036</td>\n",
       "      <td>115.040161</td>\n",
       "      <td>89407.554688</td>\n",
       "      <td>3.462372e+05</td>\n",
       "      <td>0.182732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 02:00:00</th>\n",
       "      <td>2.208340</td>\n",
       "      <td>0.863045</td>\n",
       "      <td>282.586731</td>\n",
       "      <td>302.501190</td>\n",
       "      <td>67.491943</td>\n",
       "      <td>89435.031250</td>\n",
       "      <td>1.938838e+04</td>\n",
       "      <td>0.255795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          u10       v10         d2m         t2m          blh  \\\n",
       "2023-08-01 00:00:00 -3.738469 -1.559424  293.021576  304.916901  1102.932129   \n",
       "2023-08-01 01:00:00 -3.776742 -1.448954  293.048981  304.282684   929.288391   \n",
       "2023-08-01 02:00:00 -4.739501 -1.033637  293.317322  301.812622   791.130859   \n",
       "2023-08-02 00:00:00 -3.386415 -2.400684  294.241333  306.335236   845.018921   \n",
       "2023-08-02 01:00:00 -3.479061 -2.286000  294.416901  305.872009   700.480469   \n",
       "...                       ...       ...         ...         ...          ...   \n",
       "2023-09-02 01:00:00 -1.653327 -1.693710  287.647888  305.156036   124.590942   \n",
       "2023-09-02 02:00:00 -2.278763 -1.861523  287.411530  298.941101    81.365234   \n",
       "2023-09-03 00:00:00  2.700427  0.106424  285.069061  307.079865   742.923950   \n",
       "2023-09-03 01:00:00  2.448156  0.325350  283.627228  307.212036   115.040161   \n",
       "2023-09-03 02:00:00  2.208340  0.863045  282.586731  302.501190    67.491943   \n",
       "\n",
       "                               sp          ssrd       tcc        tp   lat  \\\n",
       "2023-08-01 00:00:00  93218.429688  1.368522e+06  0.189141  0.000000  40.0   \n",
       "2023-08-01 01:00:00  93237.242188  6.759111e+05  0.124334  0.000000  40.0   \n",
       "2023-08-01 02:00:00  93295.015625  1.279279e+05  0.736759  0.000000  40.0   \n",
       "2023-08-02 00:00:00  93122.921875  1.121802e+06  0.028963  0.000003  40.0   \n",
       "2023-08-02 01:00:00  93119.210938  3.878394e+05  0.099370  0.000000  40.0   \n",
       "...                           ...           ...       ...       ...   ...   \n",
       "2023-09-02 01:00:00  89434.921875  4.045395e+05  0.351014  0.000000  43.0   \n",
       "2023-09-02 02:00:00  89471.640625  2.232738e+04  0.433720  0.000000  43.0   \n",
       "2023-09-03 00:00:00  89419.492188  7.392030e+05  0.350495  0.000000  43.0   \n",
       "2023-09-03 01:00:00  89407.554688  3.462372e+05  0.182732  0.000000  43.0   \n",
       "2023-09-03 02:00:00  89435.031250  1.938838e+04  0.255795  0.000000  43.0   \n",
       "\n",
       "                       lon  \n",
       "2023-08-01 00:00:00 -100.0  \n",
       "2023-08-01 01:00:00 -100.0  \n",
       "2023-08-01 02:00:00 -100.0  \n",
       "2023-08-02 00:00:00 -100.0  \n",
       "2023-08-02 01:00:00 -100.0  \n",
       "...                    ...  \n",
       "2023-09-02 01:00:00 -103.0  \n",
       "2023-09-02 02:00:00 -103.0  \n",
       "2023-09-03 00:00:00 -103.0  \n",
       "2023-09-03 01:00:00 -103.0  \n",
       "2023-09-03 02:00:00 -103.0  \n",
       "\n",
       "[72 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.era5_area_dataframe(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],filepath=r'./normet/datasets/ERA5_netcdf/era5_data_[40.0, 43.0]_[-103.0, -100.0].nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02050f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Aberdeen City',\n",
       " 'Armagh',\n",
       " 'Powys',\n",
       " 'Midlothian',\n",
       " 'Ballymena',\n",
       " 'Barnsley',\n",
       " 'North Devon',\n",
       " 'Bath and North East Somerset',\n",
       " 'Belfast',\n",
       " 'Stockton-on-Tees',\n",
       " 'Bassetlaw',\n",
       " 'Wirral',\n",
       " 'Birmingham',\n",
       " 'Bromsgrove',\n",
       " 'Blackburn with Darwen',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Hertsmere',\n",
       " 'Melton',\n",
       " 'Bournemouth',\n",
       " 'Bradford',\n",
       " 'Hounslow',\n",
       " 'Brighton and Hove',\n",
       " 'Bristol, City of',\n",
       " 'Bromley',\n",
       " 'East Staffordshire',\n",
       " 'Bury',\n",
       " 'North Hertfordshire',\n",
       " 'Cambridge',\n",
       " 'Camden',\n",
       " 'Cannock Chase',\n",
       " 'Canterbury',\n",
       " 'Cardiff',\n",
       " 'Carlisle',\n",
       " 'Westminster',\n",
       " 'South Somerset',\n",
       " 'Medway',\n",
       " 'Monmouthshire',\n",
       " 'Chesterfield',\n",
       " 'Test Valley',\n",
       " 'Christchurch',\n",
       " 'Coventry',\n",
       " 'Cheshire East',\n",
       " 'Torfaen',\n",
       " 'Derby',\n",
       " 'Derry',\n",
       " 'Kirklees',\n",
       " 'Doncaster',\n",
       " 'West Dunbartonshire',\n",
       " 'Dumfries and Galloway',\n",
       " 'Dundee City',\n",
       " 'Ealing',\n",
       " 'South Lanarkshire',\n",
       " 'Eastbourne',\n",
       " 'Edinburgh, City of',\n",
       " 'Exeter',\n",
       " 'Wakefield',\n",
       " 'Highland',\n",
       " 'Glasgow City',\n",
       " 'Salford',\n",
       " 'Falkirk',\n",
       " 'Eden',\n",
       " 'Inverclyde',\n",
       " 'Caerphilly',\n",
       " 'Haringey',\n",
       " 'Hartlepool',\n",
       " 'Vale of White Horse',\n",
       " 'Ryedale',\n",
       " 'East Devon',\n",
       " 'Reigate and Banstead',\n",
       " 'Kingston upon Hull, City of',\n",
       " 'North East Lincolnshire',\n",
       " 'High Peak',\n",
       " 'Warwick',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Herefordshire, County of',\n",
       " 'Shetland Islands',\n",
       " 'Lincoln',\n",
       " 'Liverpool',\n",
       " 'Kingston upon Thames',\n",
       " 'Bexley',\n",
       " 'Brent',\n",
       " 'Castle Point',\n",
       " 'Kensington and Chelsea',\n",
       " 'Greenwich',\n",
       " 'Hackney',\n",
       " 'Hillingdon',\n",
       " 'Harrow',\n",
       " 'Lewisham',\n",
       " 'Islington',\n",
       " 'Southwark',\n",
       " 'Sutton',\n",
       " 'Richmond',\n",
       " 'Wandsworth',\n",
       " 'Fermanagh',\n",
       " 'Wealden',\n",
       " 'Luton',\n",
       " nan,\n",
       " 'Manchester',\n",
       " 'Harborough',\n",
       " 'Middlesbrough',\n",
       " 'Milton Keynes',\n",
       " 'Flintshire',\n",
       " 'Pembrokeshire',\n",
       " 'Newcastle upon Tyne',\n",
       " 'Newport',\n",
       " 'Northampton',\n",
       " 'Norwich',\n",
       " 'Nottingham',\n",
       " 'Sandwell',\n",
       " 'Oxford',\n",
       " 'Scottish Borders',\n",
       " 'Plymouth',\n",
       " 'Neath Port Talbot',\n",
       " 'Portsmouth',\n",
       " 'Preston',\n",
       " 'Reading',\n",
       " 'Redcar and Cleveland',\n",
       " 'Rotherham',\n",
       " 'Cornwall',\n",
       " 'Central Bedfordshire',\n",
       " 'North Lincolnshire',\n",
       " 'Oldham',\n",
       " 'Sheffield',\n",
       " 'Suffolk Coastal',\n",
       " 'Southampton',\n",
       " 'Southend-on-Sea',\n",
       " 'St. Helens',\n",
       " 'Tendring',\n",
       " 'Thurrock',\n",
       " 'Stevenage',\n",
       " 'Bedford',\n",
       " 'Stockport',\n",
       " 'Stoke on Trent',\n",
       " 'Horsham',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Swindon',\n",
       " 'Telford and Wrekin',\n",
       " 'Tower Hamlets',\n",
       " 'Walsall',\n",
       " 'Warrington',\n",
       " 'North Norfolk',\n",
       " 'East Cambridgeshire',\n",
       " 'Halton',\n",
       " 'Wigan',\n",
       " 'Wolverhampton',\n",
       " 'Worthing',\n",
       " 'Lancaster',\n",
       " 'Wrexham',\n",
       " 'Teignbridge',\n",
       " 'York']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.UK_AURN_metadata(path='./normet/datasets/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178f4fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading metadata file...\n",
      "100% [..........................................................] 32576 / 32576Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2016\n",
      "100% [........................................................] 169802 / 169802Creating .csv file for  Birmingham A4540 Roadside\n",
      "Downloading data file for  Birmingham Acocks Green  in  2015\n",
      "100% [........................................................] 471952 / 471952Downloading data file for  Birmingham Acocks Green  in  2016\n",
      "100% [........................................................] 478822 / 478822Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Tyburn  in  2015\n",
      "100% [........................................................] 752216 / 752216Downloading data file for  Birmingham Tyburn  in  2016\n",
      "100% [........................................................] 744705 / 744705Creating .csv file for  Birmingham Tyburn\n",
      "Downloading data file for  Birmingham Tyburn Roadside  in  2015\n",
      "100% [........................................................] 605271 / 605271Downloading data file for  Birmingham Tyburn Roadside  in  2016\n",
      "100% [........................................................] 418137 / 418137Creating .csv file for  Birmingham Tyburn Roadside\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Birmingham'],path='./normet/datasets/')\n",
    "#gd.UK_AURN_download([2015,2016],manual_selection=False,path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbf5d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Manchester Piccadilly  in  2015\n",
      "100% [........................................................] 668772 / 668772Downloading data file for  Manchester Piccadilly  in  2016\n",
      "100% [........................................................] 636433 / 636433Creating .csv file for  Manchester Piccadilly\n",
      "Downloading data file for  Manchester Sharston  in  2015\n",
      "Could not download data from  2015  for  Manchester Sharston\n",
      "Downloading data file for  Manchester Sharston  in  2016\n",
      "100% [........................................................] 265610 / 265610Creating .csv file for  Manchester Sharston\n",
      "Downloading data file for  Manchester South  in  2015\n",
      "100% [........................................................] 322628 / 322628Downloading data file for  Manchester South  in  2016\n",
      "100% [..........................................................] 28254 / 28254Creating .csv file for  Manchester South\n",
      "Downloading data file for  Manchester Town Hall  in  2015\n",
      "Could not download data from  2015  for  Manchester Town Hall\n",
      "Downloading data file for  Manchester Town Hall  in  2016\n",
      "Could not download data from  2016  for  Manchester Town Hall\n",
      "No data could be downloaded for  Manchester Town Hall\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham A4540 Roadside  in  2016\n",
      "Creating .csv file for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham Acocks Green  in  2015\n",
      "Data file already exists Birmingham Acocks Green  in  2016\n",
      "Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Data file already exists Birmingham Tyburn  in  2015\n",
      "Data file already exists Birmingham Tyburn  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2015\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn Roadside\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Manchester','Birmingham'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda99090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Please select the authorities in the below list ['Aberdeen City', 'Armagh', 'Powys', 'Midlothian', 'Ballymena', 'Barnsley', 'North Devon', 'Bath and North East Somerset', 'Belfast', 'Stockton-on-Tees', 'Bassetlaw', 'Wirral', 'Birmingham', 'Bromsgrove', 'Blackburn with Darwen', 'Blackpool', 'Bolton', 'Hertsmere', 'Melton', 'Bournemouth', 'Bradford', 'Hounslow', 'Brighton and Hove', 'Bristol, City of', 'Bromley', 'East Staffordshire', 'Bury', 'North Hertfordshire', 'Cambridge', 'Camden', 'Cannock Chase', 'Canterbury', 'Cardiff', 'Carlisle', 'Westminster', 'South Somerset', 'Medway', 'Monmouthshire', 'Chesterfield', 'Test Valley', 'Christchurch', 'Coventry', 'Cheshire East', 'Torfaen', 'Derby', 'Derry', 'Kirklees', 'Doncaster', 'West Dunbartonshire', 'Dumfries and Galloway', 'Dundee City', 'Ealing', 'South Lanarkshire', 'Eastbourne', 'Edinburgh, City of', 'Exeter', 'Wakefield', 'Highland', 'Glasgow City', 'Salford', 'Falkirk', 'Eden', 'Inverclyde', 'Caerphilly', 'Haringey', 'Hartlepool', 'Vale of White Horse', 'Ryedale', 'East Devon', 'Reigate and Banstead', 'Kingston upon Hull, City of', 'North East Lincolnshire', 'High Peak', 'Warwick', 'Leeds', 'Leicester', 'Herefordshire, County of', 'Shetland Islands', 'Lincoln', 'Liverpool', 'Kingston upon Thames', 'Bexley', 'Brent', 'Castle Point', 'Kensington and Chelsea', 'Greenwich', 'Hackney', 'Hillingdon', 'Harrow', 'Lewisham', 'Islington', 'Southwark', 'Sutton', 'Richmond', 'Wandsworth', 'Fermanagh', 'Wealden', 'Luton', nan, 'Manchester', 'Harborough', 'Middlesbrough', 'Milton Keynes', 'Flintshire', 'Pembrokeshire', 'Newcastle upon Tyne', 'Newport', 'Northampton', 'Norwich', 'Nottingham', 'Sandwell', 'Oxford', 'Scottish Borders', 'Plymouth', 'Neath Port Talbot', 'Portsmouth', 'Preston', 'Reading', 'Redcar and Cleveland', 'Rotherham', 'Cornwall', 'Central Bedfordshire', 'North Lincolnshire', 'Oldham', 'Sheffield', 'Suffolk Coastal', 'Southampton', 'Southend-on-Sea', 'St. Helens', 'Tendring', 'Thurrock', 'Stevenage', 'Bedford', 'Stockport', 'Stoke on Trent', 'Horsham', 'Sunderland', 'Swansea', 'Swindon', 'Telford and Wrekin', 'Tower Hamlets', 'Walsall', 'Warrington', 'North Norfolk', 'East Cambridgeshire', 'Halton', 'Wigan', 'Wolverhampton', 'Worthing', 'Lancaster', 'Wrexham', 'Teignbridge', 'York']\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Glasgow'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacadc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Glasgow Centre  in  2015\n",
      "Could not download data from  2015  for  Glasgow Centre\n",
      "Downloading data file for  Glasgow Centre  in  2016\n",
      "Could not download data from  2016  for  Glasgow Centre\n",
      "No data could be downloaded for  Glasgow Centre\n",
      "Downloading data file for  Glasgow City Chambers  in  2015\n",
      "Could not download data from  2015  for  Glasgow City Chambers\n",
      "Downloading data file for  Glasgow City Chambers  in  2016\n",
      "Could not download data from  2016  for  Glasgow City Chambers\n",
      "No data could be downloaded for  Glasgow City Chambers\n",
      "Downloading data file for  Glasgow Great Western Road  in  2015\n",
      "100% [........................................................] 213014 / 213014Downloading data file for  Glasgow Great Western Road  in  2016\n",
      "100% [........................................................] 208118 / 208118Could not create Ox entry for  GGWR\n",
      "Creating .csv file for  Glasgow Great Western Road\n",
      "Downloading data file for  Glasgow High Street  in  2015\n",
      "100% [........................................................] 437909 / 437909Downloading data file for  Glasgow High Street  in  2016\n",
      "100% [........................................................] 491208 / 491208Could not create Ox entry for  GHSR\n",
      "Creating .csv file for  Glasgow High Street\n",
      "Downloading data file for  Glasgow Hope St  in  2015\n",
      "Could not download data from  2015  for  Glasgow Hope St\n",
      "Downloading data file for  Glasgow Hope St  in  2016\n",
      "Could not download data from  2016  for  Glasgow Hope St\n",
      "No data could be downloaded for  Glasgow Hope St\n",
      "Downloading data file for  Glasgow Kerbside  in  2015\n",
      "100% [........................................................] 218988 / 218988Downloading data file for  Glasgow Kerbside  in  2016\n",
      "100% [........................................................] 219981 / 219981Could not create Ox entry for  GLA4\n",
      "Creating .csv file for  Glasgow Kerbside\n",
      "Downloading data file for  Glasgow Townhead  in  2015\n",
      "100% [........................................................] 582060 / 582060Downloading data file for  Glasgow Townhead  in  2016\n",
      "100% [........................................................] 590075 / 590075Creating .csv file for  Glasgow Townhead\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Glasgow City'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d757db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Aberdeen  in  2015\n",
      "100% [........................................................] 585418 / 585418Downloading data file for  Aberdeen  in  2016\n",
      "100% [........................................................] 584495 / 584495Creating .csv file for  Aberdeen\n",
      "Downloading data file for  Aberdeen Erroll Park  in  2015\n",
      "Could not download data from  2015  for  Aberdeen Erroll Park\n",
      "Downloading data file for  Aberdeen Erroll Park  in  2016\n",
      "Could not download data from  2016  for  Aberdeen Erroll Park\n",
      "No data could be downloaded for  Aberdeen Erroll Park\n",
      "Downloading data file for  Aberdeen Union Street Roadside  in  2015\n",
      "100% [........................................................] 218013 / 218013Downloading data file for  Aberdeen Union Street Roadside  in  2016\n",
      "100% [........................................................] 212952 / 212952Could not create Ox entry for  ABD7\n",
      "Creating .csv file for  Aberdeen Union Street Roadside\n",
      "Downloading data file for  Aberdeen Wellington Road  in  2015\n",
      "Could not download data from  2015  for  Aberdeen Wellington Road\n",
      "Downloading data file for  Aberdeen Wellington Road  in  2016\n",
      "100% [........................................................] 194601 / 194601Could not create Ox entry for  ABD8\n",
      "Creating .csv file for  Aberdeen Wellington Road\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Armagh Roadside  in  2015\n",
      "100% [........................................................] 252255 / 252255Downloading data file for  Armagh Roadside  in  2016\n",
      "100% [........................................................] 329828 / 329828Could not create Ox entry for  ARM6\n",
      "Creating .csv file for  Armagh Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Aston Hill  in  2015\n",
      "100% [........................................................] 291896 / 291896Downloading data file for  Aston Hill  in  2016\n",
      "100% [........................................................] 293203 / 293203Creating .csv file for  Aston Hill\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Auchencorth Moss  in  2015\n",
      "100% [........................................................] 515828 / 515828Downloading data file for  Auchencorth Moss  in  2016\n",
      "100% [........................................................] 687514 / 687514Could not create Ox entry for  ACTH\n",
      "Could not create NOx entry for  ACTH\n",
      "Creating .csv file for  Auchencorth Moss\n",
      "Downloading data file for  Bush Estate  in  2015\n",
      "100% [........................................................] 299677 / 299677Downloading data file for  Bush Estate  in  2016\n",
      "100% [........................................................] 305206 / 305206Creating .csv file for  Bush Estate\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Ballymena Antrim Road  in  2015\n",
      "Could not download data from  2015  for  Ballymena Antrim Road\n",
      "Downloading data file for  Ballymena Antrim Road  in  2016\n",
      "Could not download data from  2016  for  Ballymena Antrim Road\n",
      "No data could be downloaded for  Ballymena Antrim Road\n",
      "Downloading data file for  Ballymena Ballykeel  in  2015\n",
      "100% [........................................................] 263188 / 263188Downloading data file for  Ballymena Ballykeel  in  2016\n",
      "100% [........................................................] 346449 / 346449Could not create Ox entry for  BALM\n",
      "Creating .csv file for  Ballymena Ballykeel\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Barnsley  in  2015\n",
      "Could not download data from  2015  for  Barnsley\n",
      "Downloading data file for  Barnsley  in  2016\n",
      "Could not download data from  2016  for  Barnsley\n",
      "No data could be downloaded for  Barnsley\n",
      "Downloading data file for  Barnsley 12  in  2015\n",
      "Could not download data from  2015  for  Barnsley 12\n",
      "Downloading data file for  Barnsley 12  in  2016\n",
      "Could not download data from  2016  for  Barnsley 12\n",
      "No data could be downloaded for  Barnsley 12\n",
      "Downloading data file for  Barnsley Gawber  in  2015\n",
      "100% [........................................................] 497639 / 497639Downloading data file for  Barnsley Gawber  in  2016\n",
      "100% [........................................................] 505746 / 505746Creating .csv file for  Barnsley Gawber\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Barnstaple A39  in  2015\n",
      "100% [........................................................] 341621 / 341621Downloading data file for  Barnstaple A39  in  2016\n",
      "100% [........................................................] 349923 / 349923Could not create Ox entry for  BPLE\n",
      "Could not create NOx entry for  BPLE\n",
      "Creating .csv file for  Barnstaple A39\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Bath A4 Roadside  in  2015\n",
      "Could not download data from  2015  for  Bath A4 Roadside\n",
      "Downloading data file for  Bath A4 Roadside  in  2016\n",
      "Could not download data from  2016  for  Bath A4 Roadside\n",
      "No data could be downloaded for  Bath A4 Roadside\n",
      "Downloading data file for  Bath Roadside  in  2015\n",
      "100% [........................................................] 217200 / 217200Downloading data file for  Bath Roadside  in  2016\n",
      "100% [........................................................] 213328 / 213328Could not create Ox entry for  BATH\n",
      "Creating .csv file for  Bath Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Belfast Centre  in  2015\n",
      "100% [........................................................] 838414 / 838414Downloading data file for  Belfast Centre  in  2016\n",
      "100% [........................................................] 854053 / 854053Creating .csv file for  Belfast Centre\n",
      "Downloading data file for  Belfast Clara St  in  2015\n",
      "Could not download data from  2015  for  Belfast Clara St\n",
      "Downloading data file for  Belfast Clara St  in  2016\n",
      "Could not download data from  2016  for  Belfast Clara St\n",
      "No data could be downloaded for  Belfast Clara St\n",
      "Downloading data file for  Belfast East  in  2015\n",
      "Could not download data from  2015  for  Belfast East\n",
      "Downloading data file for  Belfast East  in  2016\n",
      "Could not download data from  2016  for  Belfast East\n",
      "No data could be downloaded for  Belfast East\n",
      "Downloading data file for  Belfast South  in  2015\n",
      "Could not download data from  2015  for  Belfast South\n",
      "Downloading data file for  Belfast South  in  2016\n",
      "Could not download data from  2016  for  Belfast South\n",
      "No data could be downloaded for  Belfast South\n",
      "Downloading data file for  Belfast Stockman's Lane  in  2015\n",
      "100% [........................................................] 292194 / 292194Downloading data file for  Belfast Stockman's Lane  in  2016\n",
      "100% [........................................................] 292667 / 292667Could not create Ox entry for  BEL1\n",
      "Creating .csv file for  Belfast Stockman's Lane\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Billingham  in  2015\n",
      "100% [........................................................] 207003 / 207003Downloading data file for  Billingham  in  2016\n",
      "100% [........................................................] 206509 / 206509Could not create Ox entry for  BIL\n",
      "Creating .csv file for  Billingham\n",
      "Downloading data file for  Stockton-on-Tees A1305 Roadside  in  2015\n",
      "100% [........................................................] 142913 / 142913Downloading data file for  Stockton-on-Tees A1305 Roadside  in  2016\n",
      "100% [........................................................] 349061 / 349061Could not create Ox entry for  SOTR\n",
      "Creating .csv file for  Stockton-on-Tees A1305 Roadside\n",
      "Downloading data file for  Stockton-on-Tees Eaglescliffe  in  2015\n",
      "100% [........................................................] 319136 / 319136Downloading data file for  Stockton-on-Tees Eaglescliffe  in  2016\n",
      "100% [........................................................] 307345 / 307345Could not create Ox entry for  EAGL\n",
      "Creating .csv file for  Stockton-on-Tees Eaglescliffe\n",
      "Downloading data file for  Stockton-on-Tees Yarm  in  2015\n",
      "Could not download data from  2015  for  Stockton-on-Tees Yarm\n",
      "Downloading data file for  Stockton-on-Tees Yarm  in  2016\n",
      "Could not download data from  2016  for  Stockton-on-Tees Yarm\n",
      "No data could be downloaded for  Stockton-on-Tees Yarm\n",
      "Metadata file already exists, skipping download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid end year, out of range for  Bassetlaw\n",
      "Invalid end year. The latest you can select for  Bassetlaw  is  1991\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birkenhead Borough Road  in  2015\n",
      "Could not download data from  2015  for  Birkenhead Borough Road\n",
      "Downloading data file for  Birkenhead Borough Road  in  2016\n",
      "100% [..........................................................] 65127 / 65127Could not create Ox entry for  BBRD\n",
      "Creating .csv file for  Birkenhead Borough Road\n",
      "Downloading data file for  Wirral Tranmere  in  2015\n",
      "100% [........................................................] 445831 / 445831Downloading data file for  Wirral Tranmere  in  2016\n",
      "100% [........................................................] 460800 / 460800Creating .csv file for  Wirral Tranmere\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham A4540 Roadside  in  2016\n",
      "Creating .csv file for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham Acocks Green  in  2015\n",
      "Data file already exists Birmingham Acocks Green  in  2016\n",
      "Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Data file already exists Birmingham Tyburn  in  2015\n",
      "Data file already exists Birmingham Tyburn  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2015\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Invalid end year, out of range for  Bromsgrove\n",
      "Invalid end year. The latest you can select for  Bromsgrove  is  1978\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Blackburn Accrington Road  in  2015\n",
      "100% [........................................................] 201802 / 201802Downloading data file for  Blackburn Accrington Road  in  2016\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb77b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
