{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fdb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2602bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import normet.getdata as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e29c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 21:09:00,995 INFO Welcome to the CDS\n",
      "2023-09-12 21:09:01,001 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 21:09:01,001 INFO Welcome to the CDS\n",
      "2023-09-12 21:09:01,015 INFO Welcome to the CDS\n",
      "2023-09-12 21:09:01,016 INFO Welcome to the CDS\n",
      "2023-09-12 21:09:01,019 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 21:09:01,020 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 21:09:01,021 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 21:09:01,101 INFO Request is queued\n",
      "2023-09-12 21:09:01,119 INFO Request is queued\n",
      "2023-09-12 21:09:01,129 INFO Request is queued\n",
      "2023-09-12 21:09:01,145 INFO Request is queued\n",
      "2023-09-12 21:09:02,205 INFO Request is running\n",
      "2023-09-12 21:10:55,239 INFO Request is completed\n",
      "2023-09-12 21:10:55,242 INFO Request is running\n",
      "2023-09-12 21:10:55,243 INFO Downloading https://download-0002-clone.copernicus-climate.eu/cache-compute-0002/cache/data0/adaptor.mars.internal-1694549413.6127057-14891-13-b78cae93-51de-4aa9-9479-e1237b585407.nc to ./normet/datasets/ERA5_netcdf/era5_data_43.0_-103.0.nc (66.7K)\n",
      "2023-09-12 21:10:55,780 INFO Download rate 125.1K/s                             \n",
      "2023-09-12 21:11:52,939 INFO Request is completed\n",
      "2023-09-12 21:11:52,941 INFO Downloading https://download-0012-clone.copernicus-climate.eu/cache-compute-0012/cache/data6/adaptor.mars.internal-1694549498.2232108-31793-6-f285f768-3626-4944-a282-c67e723b5598.nc to ./normet/datasets/ERA5_netcdf/era5_data_41.0_-101.0.nc (66.7K)\n",
      "2023-09-12 21:11:52,962 INFO Request is running\n",
      "2023-09-12 21:11:52,996 INFO Request is completed\n",
      "2023-09-12 21:11:52,998 INFO Downloading https://download-0000-clone.copernicus-climate.eu/cache-compute-0000/cache/data1/adaptor.mars.internal-1694549465.4475033-6507-5-cee55b5f-6a4e-4542-a653-18f1f7dd20cc.nc to ./normet/datasets/ERA5_netcdf/era5_data_40.0_-100.0.nc (66.7K)\n",
      "  0%|                                               | 0.00/66.7k [00:00<?, ?B/s]\n",
      "2023-09-12 21:11:53,433 INFO Download rate 136K/s                               \u001b[A\n",
      "\n",
      " 51%|███████████████████▊                   | 34.0k/66.7k [00:00<00:00, 300kB/s]\u001b[A\n",
      "                                                                                \u001b[A2023-09-12 21:11:53,459 INFO Download rate 145.1K/s\n",
      "2023-09-12 21:13:19,762 INFO Request is completed\n",
      "2023-09-12 21:13:19,763 INFO Downloading https://download-0020.copernicus-climate.eu/cache-compute-0020/cache/data5/adaptor.mars.internal-1694549533.684541-22908-6-c4d0033e-8fec-4d0e-a823-ff06b5bcd15d.nc to ./normet/datasets/ERA5_netcdf/era5_data_42.0_-102.0.nc (66.7K)\n",
      "2023-09-12 21:13:20,235 INFO Download rate 142K/s                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Thread(Thread-8 (download_era5_worker), stopped 13136969728)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.download_era5(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],\n",
    "              year_range = [ '2023'],month_range = ['06','07','08','09'],time_range=['00:00','06:00'],\n",
    "              path=r'./normet/datasets/ERA5_netcdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79179811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=gd.era5_dataframe(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],path=r'./normet/datasets/ERA5_netcdf/',n_cores=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62032b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>blh</th>\n",
       "      <th>sp</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-01 00:00:00</th>\n",
       "      <td>-3.281632</td>\n",
       "      <td>2.028531</td>\n",
       "      <td>287.550537</td>\n",
       "      <td>300.063568</td>\n",
       "      <td>1759.959229</td>\n",
       "      <td>92618.492188</td>\n",
       "      <td>1.014072e+06</td>\n",
       "      <td>0.997742</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 06:00:00</th>\n",
       "      <td>-0.748762</td>\n",
       "      <td>3.225044</td>\n",
       "      <td>288.601135</td>\n",
       "      <td>291.967072</td>\n",
       "      <td>172.274292</td>\n",
       "      <td>92777.703125</td>\n",
       "      <td>6.250000e-02</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-02 00:00:00</th>\n",
       "      <td>-3.980443</td>\n",
       "      <td>4.070179</td>\n",
       "      <td>290.849457</td>\n",
       "      <td>296.112549</td>\n",
       "      <td>758.661377</td>\n",
       "      <td>92744.296875</td>\n",
       "      <td>7.966119e+05</td>\n",
       "      <td>0.514214</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-02 06:00:00</th>\n",
       "      <td>-1.452486</td>\n",
       "      <td>5.936829</td>\n",
       "      <td>289.287689</td>\n",
       "      <td>291.675018</td>\n",
       "      <td>615.429443</td>\n",
       "      <td>93030.421875</td>\n",
       "      <td>6.250000e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-03 00:00:00</th>\n",
       "      <td>-1.935384</td>\n",
       "      <td>4.124088</td>\n",
       "      <td>288.159637</td>\n",
       "      <td>291.883698</td>\n",
       "      <td>1228.494385</td>\n",
       "      <td>92911.953125</td>\n",
       "      <td>8.563941e+05</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-05 06:00:00</th>\n",
       "      <td>7.213226</td>\n",
       "      <td>0.261553</td>\n",
       "      <td>284.015137</td>\n",
       "      <td>290.079498</td>\n",
       "      <td>1182.246216</td>\n",
       "      <td>88919.343750</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06 00:00:00</th>\n",
       "      <td>-1.841030</td>\n",
       "      <td>-3.006474</td>\n",
       "      <td>279.860870</td>\n",
       "      <td>292.103516</td>\n",
       "      <td>879.621460</td>\n",
       "      <td>90070.835938</td>\n",
       "      <td>9.340269e+05</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06 06:00:00</th>\n",
       "      <td>-0.231133</td>\n",
       "      <td>1.879773</td>\n",
       "      <td>279.632996</td>\n",
       "      <td>283.753540</td>\n",
       "      <td>46.483887</td>\n",
       "      <td>90174.726562</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 00:00:00</th>\n",
       "      <td>-2.133496</td>\n",
       "      <td>0.209741</td>\n",
       "      <td>282.347443</td>\n",
       "      <td>300.340179</td>\n",
       "      <td>764.380737</td>\n",
       "      <td>89621.882812</td>\n",
       "      <td>1.021833e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07 06:00:00</th>\n",
       "      <td>-1.816399</td>\n",
       "      <td>4.103830</td>\n",
       "      <td>282.551575</td>\n",
       "      <td>290.238312</td>\n",
       "      <td>276.069458</td>\n",
       "      <td>89617.492188</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          u10       v10         d2m         t2m          blh  \\\n",
       "2023-06-01 00:00:00 -3.281632  2.028531  287.550537  300.063568  1759.959229   \n",
       "2023-06-01 06:00:00 -0.748762  3.225044  288.601135  291.967072   172.274292   \n",
       "2023-06-02 00:00:00 -3.980443  4.070179  290.849457  296.112549   758.661377   \n",
       "2023-06-02 06:00:00 -1.452486  5.936829  289.287689  291.675018   615.429443   \n",
       "2023-06-03 00:00:00 -1.935384  4.124088  288.159637  291.883698  1228.494385   \n",
       "...                       ...       ...         ...         ...          ...   \n",
       "2023-09-05 06:00:00  7.213226  0.261553  284.015137  290.079498  1182.246216   \n",
       "2023-09-06 00:00:00 -1.841030 -3.006474  279.860870  292.103516   879.621460   \n",
       "2023-09-06 06:00:00 -0.231133  1.879773  279.632996  283.753540    46.483887   \n",
       "2023-09-07 00:00:00 -2.133496  0.209741  282.347443  300.340179   764.380737   \n",
       "2023-09-07 06:00:00 -1.816399  4.103830  282.551575  290.238312   276.069458   \n",
       "\n",
       "                               sp          ssrd       tcc        tp   lat  \\\n",
       "2023-06-01 00:00:00  92618.492188  1.014072e+06  0.997742  0.000102  40.0   \n",
       "2023-06-01 06:00:00  92777.703125  6.250000e-02  0.998871  0.000000  40.0   \n",
       "2023-06-02 00:00:00  92744.296875  7.966119e+05  0.514214  0.000007  40.0   \n",
       "2023-06-02 06:00:00  93030.421875  6.250000e-02  1.000000  0.000013  40.0   \n",
       "2023-06-03 00:00:00  92911.953125  8.563941e+05  0.998871  0.000222  40.0   \n",
       "...                           ...           ...       ...       ...   ...   \n",
       "2023-09-05 06:00:00  88919.343750  0.000000e+00  0.018220  0.000000  43.0   \n",
       "2023-09-06 00:00:00  90070.835938  9.340269e+05  0.005097  0.000000  43.0   \n",
       "2023-09-06 06:00:00  90174.726562  0.000000e+00  0.000000  0.000000  43.0   \n",
       "2023-09-07 00:00:00  89621.882812  1.021833e+06  0.000000  0.000000  43.0   \n",
       "2023-09-07 06:00:00  89617.492188  0.000000e+00  0.015229  0.000000  43.0   \n",
       "\n",
       "                       lon  \n",
       "2023-06-01 00:00:00 -100.0  \n",
       "2023-06-01 06:00:00 -100.0  \n",
       "2023-06-02 00:00:00 -100.0  \n",
       "2023-06-02 06:00:00 -100.0  \n",
       "2023-06-03 00:00:00 -100.0  \n",
       "...                    ...  \n",
       "2023-09-05 06:00:00 -103.0  \n",
       "2023-09-06 00:00:00 -103.0  \n",
       "2023-09-06 06:00:00 -103.0  \n",
       "2023-09-07 00:00:00 -103.0  \n",
       "2023-09-07 06:00:00 -103.0  \n",
       "\n",
       "[792 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a8f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 18:12:39,314 INFO Welcome to the CDS\n",
      "2023-09-12 18:12:39,316 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-09-12 18:12:39,481 INFO Request is queued\n",
      "2023-09-12 18:12:40,564 INFO Request is running\n",
      "2023-09-12 18:15:31,341 INFO Request is completed\n",
      "2023-09-12 18:15:31,343 INFO Downloading https://download-0004-clone.copernicus-climate.eu/cache-compute-0004/cache/data7/adaptor.mars.internal-1694538877.8243256-18034-4-d7c34fe7-eef6-40b9-afa4-c5376cc5c163.nc to ./normet/datasets/ERA5_netcdf/era5_data_[40.0, 43.0]_[-103.0, -100.0].nc (1.7M)\n",
      "2023-09-12 18:15:32,178 INFO Download rate 2.1M/s                               \n"
     ]
    }
   ],
   "source": [
    "gd.download_era5_area(lat_lim = [40.0, 43.0],lon_lim = [-103.0,-100.0],\n",
    "              year_range = ['2021', '2022','2023'],\n",
    "              day_range = ['01', '02', '03'],time_range = ['00:00', '01:00', '02:00'],path=r'./normet/datasets/ERA5_netcdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca9b01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>blh</th>\n",
       "      <th>sp</th>\n",
       "      <th>ssrd</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>-2.358809</td>\n",
       "      <td>2.160340</td>\n",
       "      <td>268.567200</td>\n",
       "      <td>272.802277</td>\n",
       "      <td>51.293457</td>\n",
       "      <td>93271.562500</td>\n",
       "      <td>18745.0625</td>\n",
       "      <td>0.709261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 01:00:00</th>\n",
       "      <td>-2.563165</td>\n",
       "      <td>2.411218</td>\n",
       "      <td>268.716248</td>\n",
       "      <td>272.276337</td>\n",
       "      <td>37.976807</td>\n",
       "      <td>93299.015625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 02:00:00</th>\n",
       "      <td>-1.891919</td>\n",
       "      <td>2.109313</td>\n",
       "      <td>268.030609</td>\n",
       "      <td>270.362762</td>\n",
       "      <td>65.838379</td>\n",
       "      <td>93395.632812</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 00:00:00</th>\n",
       "      <td>2.033741</td>\n",
       "      <td>-2.507249</td>\n",
       "      <td>270.999023</td>\n",
       "      <td>274.355591</td>\n",
       "      <td>187.885864</td>\n",
       "      <td>93522.546875</td>\n",
       "      <td>17656.4375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 01:00:00</th>\n",
       "      <td>1.949381</td>\n",
       "      <td>-2.205017</td>\n",
       "      <td>270.840027</td>\n",
       "      <td>273.828766</td>\n",
       "      <td>136.623291</td>\n",
       "      <td>93536.796875</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.992797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-02 01:00:00</th>\n",
       "      <td>-1.653383</td>\n",
       "      <td>-1.693774</td>\n",
       "      <td>287.647797</td>\n",
       "      <td>305.155945</td>\n",
       "      <td>124.599609</td>\n",
       "      <td>89434.828125</td>\n",
       "      <td>404531.3750</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-02 02:00:00</th>\n",
       "      <td>-2.278813</td>\n",
       "      <td>-1.861572</td>\n",
       "      <td>287.411133</td>\n",
       "      <td>298.940979</td>\n",
       "      <td>81.417603</td>\n",
       "      <td>89471.734375</td>\n",
       "      <td>22329.4375</td>\n",
       "      <td>0.433720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 00:00:00</th>\n",
       "      <td>2.700260</td>\n",
       "      <td>0.106208</td>\n",
       "      <td>285.068726</td>\n",
       "      <td>307.080017</td>\n",
       "      <td>742.917358</td>\n",
       "      <td>89419.382812</td>\n",
       "      <td>739207.0000</td>\n",
       "      <td>0.350495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 01:00:00</th>\n",
       "      <td>2.448270</td>\n",
       "      <td>0.325359</td>\n",
       "      <td>283.626984</td>\n",
       "      <td>307.211517</td>\n",
       "      <td>115.032349</td>\n",
       "      <td>89407.531250</td>\n",
       "      <td>346251.8750</td>\n",
       "      <td>0.182732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-03 02:00:00</th>\n",
       "      <td>2.208280</td>\n",
       "      <td>0.863096</td>\n",
       "      <td>282.586334</td>\n",
       "      <td>302.500793</td>\n",
       "      <td>67.519043</td>\n",
       "      <td>89434.984375</td>\n",
       "      <td>19382.3125</td>\n",
       "      <td>0.255795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          u10       v10         d2m         t2m         blh  \\\n",
       "2021-01-01 00:00:00 -2.358809  2.160340  268.567200  272.802277   51.293457   \n",
       "2021-01-01 01:00:00 -2.563165  2.411218  268.716248  272.276337   37.976807   \n",
       "2021-01-01 02:00:00 -1.891919  2.109313  268.030609  270.362762   65.838379   \n",
       "2021-01-02 00:00:00  2.033741 -2.507249  270.999023  274.355591  187.885864   \n",
       "2021-01-02 01:00:00  1.949381 -2.205017  270.840027  273.828766  136.623291   \n",
       "...                       ...       ...         ...         ...         ...   \n",
       "2023-09-02 01:00:00 -1.653383 -1.693774  287.647797  305.155945  124.599609   \n",
       "2023-09-02 02:00:00 -2.278813 -1.861572  287.411133  298.940979   81.417603   \n",
       "2023-09-03 00:00:00  2.700260  0.106208  285.068726  307.080017  742.917358   \n",
       "2023-09-03 01:00:00  2.448270  0.325359  283.626984  307.211517  115.032349   \n",
       "2023-09-03 02:00:00  2.208280  0.863096  282.586334  302.500793   67.519043   \n",
       "\n",
       "                               sp         ssrd       tcc   tp   lat    lon  \n",
       "2021-01-01 00:00:00  93271.562500   18745.0625  0.709261  0.0  40.0 -100.0  \n",
       "2021-01-01 01:00:00  93299.015625       0.0625  1.000000  0.0  40.0 -100.0  \n",
       "2021-01-01 02:00:00  93395.632812       0.0625  1.000000  0.0  40.0 -100.0  \n",
       "2021-01-02 00:00:00  93522.546875   17656.4375  1.000000  0.0  40.0 -100.0  \n",
       "2021-01-02 01:00:00  93536.796875       0.0625  0.992797  0.0  40.0 -100.0  \n",
       "...                           ...          ...       ...  ...   ...    ...  \n",
       "2023-09-02 01:00:00  89434.828125  404531.3750  0.351014  0.0  43.0 -103.0  \n",
       "2023-09-02 02:00:00  89471.734375   22329.4375  0.433720  0.0  43.0 -103.0  \n",
       "2023-09-03 00:00:00  89419.382812  739207.0000  0.350495  0.0  43.0 -103.0  \n",
       "2023-09-03 01:00:00  89407.531250  346251.8750  0.182732  0.0  43.0 -103.0  \n",
       "2023-09-03 02:00:00  89434.984375   19382.3125  0.255795  0.0  43.0 -103.0  \n",
       "\n",
       "[1188 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.era5_area_dataframe(lat_list = [40.0, 41.0, 42.0,43.0],lon_list = [-100.0, -101.0, -102.0,-103.0],filepath=r'./normet/datasets/ERA5_netcdf/era5_data_[40.0, 43.0]_[-103.0, -100.0].nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02050f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Aberdeen City',\n",
       " 'Armagh',\n",
       " 'Powys',\n",
       " 'Midlothian',\n",
       " 'Ballymena',\n",
       " 'Barnsley',\n",
       " 'North Devon',\n",
       " 'Bath and North East Somerset',\n",
       " 'Belfast',\n",
       " 'Stockton-on-Tees',\n",
       " 'Bassetlaw',\n",
       " 'Wirral',\n",
       " 'Birmingham',\n",
       " 'Bromsgrove',\n",
       " 'Blackburn with Darwen',\n",
       " 'Blackpool',\n",
       " 'Bolton',\n",
       " 'Hertsmere',\n",
       " 'Melton',\n",
       " 'Bournemouth',\n",
       " 'Bradford',\n",
       " 'Hounslow',\n",
       " 'Brighton and Hove',\n",
       " 'Bristol, City of',\n",
       " 'Bromley',\n",
       " 'East Staffordshire',\n",
       " 'Bury',\n",
       " 'North Hertfordshire',\n",
       " 'Cambridge',\n",
       " 'Camden',\n",
       " 'Cannock Chase',\n",
       " 'Canterbury',\n",
       " 'Cardiff',\n",
       " 'Carlisle',\n",
       " 'Westminster',\n",
       " 'South Somerset',\n",
       " 'Medway',\n",
       " 'Monmouthshire',\n",
       " 'Chesterfield',\n",
       " 'Test Valley',\n",
       " 'Christchurch',\n",
       " 'Coventry',\n",
       " 'Cheshire East',\n",
       " 'Torfaen',\n",
       " 'Derby',\n",
       " 'Derry',\n",
       " 'Kirklees',\n",
       " 'Doncaster',\n",
       " 'West Dunbartonshire',\n",
       " 'Dumfries and Galloway',\n",
       " 'Dundee City',\n",
       " 'Ealing',\n",
       " 'South Lanarkshire',\n",
       " 'Eastbourne',\n",
       " 'Edinburgh, City of',\n",
       " 'Exeter',\n",
       " 'Wakefield',\n",
       " 'Highland',\n",
       " 'Glasgow City',\n",
       " 'Salford',\n",
       " 'Falkirk',\n",
       " 'Eden',\n",
       " 'Inverclyde',\n",
       " 'Caerphilly',\n",
       " 'Haringey',\n",
       " 'Hartlepool',\n",
       " 'Vale of White Horse',\n",
       " 'Ryedale',\n",
       " 'East Devon',\n",
       " 'Reigate and Banstead',\n",
       " 'Kingston upon Hull, City of',\n",
       " 'North East Lincolnshire',\n",
       " 'High Peak',\n",
       " 'Warwick',\n",
       " 'Leeds',\n",
       " 'Leicester',\n",
       " 'Herefordshire, County of',\n",
       " 'Shetland Islands',\n",
       " 'Lincoln',\n",
       " 'Liverpool',\n",
       " 'Kingston upon Thames',\n",
       " 'Bexley',\n",
       " 'Brent',\n",
       " 'Castle Point',\n",
       " 'Kensington and Chelsea',\n",
       " 'Greenwich',\n",
       " 'Hackney',\n",
       " 'Hillingdon',\n",
       " 'Harrow',\n",
       " 'Lewisham',\n",
       " 'Islington',\n",
       " 'Southwark',\n",
       " 'Sutton',\n",
       " 'Richmond',\n",
       " 'Wandsworth',\n",
       " 'Fermanagh',\n",
       " 'Wealden',\n",
       " 'Luton',\n",
       " nan,\n",
       " 'Manchester',\n",
       " 'Harborough',\n",
       " 'Middlesbrough',\n",
       " 'Milton Keynes',\n",
       " 'Flintshire',\n",
       " 'Pembrokeshire',\n",
       " 'Newcastle upon Tyne',\n",
       " 'Newport',\n",
       " 'Northampton',\n",
       " 'Norwich',\n",
       " 'Nottingham',\n",
       " 'Sandwell',\n",
       " 'Oxford',\n",
       " 'Scottish Borders',\n",
       " 'Plymouth',\n",
       " 'Neath Port Talbot',\n",
       " 'Portsmouth',\n",
       " 'Preston',\n",
       " 'Reading',\n",
       " 'Redcar and Cleveland',\n",
       " 'Rotherham',\n",
       " 'Cornwall',\n",
       " 'Central Bedfordshire',\n",
       " 'North Lincolnshire',\n",
       " 'Oldham',\n",
       " 'Sheffield',\n",
       " 'Suffolk Coastal',\n",
       " 'Southampton',\n",
       " 'Southend-on-Sea',\n",
       " 'St. Helens',\n",
       " 'Tendring',\n",
       " 'Thurrock',\n",
       " 'Stevenage',\n",
       " 'Bedford',\n",
       " 'Stockport',\n",
       " 'Stoke on Trent',\n",
       " 'Horsham',\n",
       " 'Sunderland',\n",
       " 'Swansea',\n",
       " 'Swindon',\n",
       " 'Telford and Wrekin',\n",
       " 'Tower Hamlets',\n",
       " 'Walsall',\n",
       " 'Warrington',\n",
       " 'North Norfolk',\n",
       " 'East Cambridgeshire',\n",
       " 'Halton',\n",
       " 'Wigan',\n",
       " 'Wolverhampton',\n",
       " 'Worthing',\n",
       " 'Lancaster',\n",
       " 'Wrexham',\n",
       " 'Teignbridge',\n",
       " 'York']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.UK_AURN_metadata(path='./normet/datasets/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178f4fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading metadata file...\n",
      "100% [..........................................................] 32576 / 32576Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2016\n",
      "100% [........................................................] 169802 / 169802Creating .csv file for  Birmingham A4540 Roadside\n",
      "Downloading data file for  Birmingham Acocks Green  in  2015\n",
      "100% [........................................................] 471952 / 471952Downloading data file for  Birmingham Acocks Green  in  2016\n",
      "100% [........................................................] 478822 / 478822Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Tyburn  in  2015\n",
      "100% [........................................................] 752216 / 752216Downloading data file for  Birmingham Tyburn  in  2016\n",
      "100% [........................................................] 744705 / 744705Creating .csv file for  Birmingham Tyburn\n",
      "Downloading data file for  Birmingham Tyburn Roadside  in  2015\n",
      "100% [........................................................] 605271 / 605271Downloading data file for  Birmingham Tyburn Roadside  in  2016\n",
      "100% [........................................................] 418137 / 418137Creating .csv file for  Birmingham Tyburn Roadside\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Birmingham'],path='./normet/datasets/')\n",
    "#gd.UK_AURN_download([2015,2016],manual_selection=False,path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbf5d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Manchester Piccadilly  in  2015\n",
      "100% [........................................................] 668772 / 668772Downloading data file for  Manchester Piccadilly  in  2016\n",
      "100% [........................................................] 636433 / 636433Creating .csv file for  Manchester Piccadilly\n",
      "Downloading data file for  Manchester Sharston  in  2015\n",
      "Could not download data from  2015  for  Manchester Sharston\n",
      "Downloading data file for  Manchester Sharston  in  2016\n",
      "100% [........................................................] 265610 / 265610Creating .csv file for  Manchester Sharston\n",
      "Downloading data file for  Manchester South  in  2015\n",
      "100% [........................................................] 322628 / 322628Downloading data file for  Manchester South  in  2016\n",
      "100% [..........................................................] 28254 / 28254Creating .csv file for  Manchester South\n",
      "Downloading data file for  Manchester Town Hall  in  2015\n",
      "Could not download data from  2015  for  Manchester Town Hall\n",
      "Downloading data file for  Manchester Town Hall  in  2016\n",
      "Could not download data from  2016  for  Manchester Town Hall\n",
      "No data could be downloaded for  Manchester Town Hall\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham A4540 Roadside  in  2016\n",
      "Creating .csv file for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham Acocks Green  in  2015\n",
      "Data file already exists Birmingham Acocks Green  in  2016\n",
      "Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Data file already exists Birmingham Tyburn  in  2015\n",
      "Data file already exists Birmingham Tyburn  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2015\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn Roadside\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Manchester','Birmingham'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda99090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Please select the authorities in the below list ['Aberdeen City', 'Armagh', 'Powys', 'Midlothian', 'Ballymena', 'Barnsley', 'North Devon', 'Bath and North East Somerset', 'Belfast', 'Stockton-on-Tees', 'Bassetlaw', 'Wirral', 'Birmingham', 'Bromsgrove', 'Blackburn with Darwen', 'Blackpool', 'Bolton', 'Hertsmere', 'Melton', 'Bournemouth', 'Bradford', 'Hounslow', 'Brighton and Hove', 'Bristol, City of', 'Bromley', 'East Staffordshire', 'Bury', 'North Hertfordshire', 'Cambridge', 'Camden', 'Cannock Chase', 'Canterbury', 'Cardiff', 'Carlisle', 'Westminster', 'South Somerset', 'Medway', 'Monmouthshire', 'Chesterfield', 'Test Valley', 'Christchurch', 'Coventry', 'Cheshire East', 'Torfaen', 'Derby', 'Derry', 'Kirklees', 'Doncaster', 'West Dunbartonshire', 'Dumfries and Galloway', 'Dundee City', 'Ealing', 'South Lanarkshire', 'Eastbourne', 'Edinburgh, City of', 'Exeter', 'Wakefield', 'Highland', 'Glasgow City', 'Salford', 'Falkirk', 'Eden', 'Inverclyde', 'Caerphilly', 'Haringey', 'Hartlepool', 'Vale of White Horse', 'Ryedale', 'East Devon', 'Reigate and Banstead', 'Kingston upon Hull, City of', 'North East Lincolnshire', 'High Peak', 'Warwick', 'Leeds', 'Leicester', 'Herefordshire, County of', 'Shetland Islands', 'Lincoln', 'Liverpool', 'Kingston upon Thames', 'Bexley', 'Brent', 'Castle Point', 'Kensington and Chelsea', 'Greenwich', 'Hackney', 'Hillingdon', 'Harrow', 'Lewisham', 'Islington', 'Southwark', 'Sutton', 'Richmond', 'Wandsworth', 'Fermanagh', 'Wealden', 'Luton', nan, 'Manchester', 'Harborough', 'Middlesbrough', 'Milton Keynes', 'Flintshire', 'Pembrokeshire', 'Newcastle upon Tyne', 'Newport', 'Northampton', 'Norwich', 'Nottingham', 'Sandwell', 'Oxford', 'Scottish Borders', 'Plymouth', 'Neath Port Talbot', 'Portsmouth', 'Preston', 'Reading', 'Redcar and Cleveland', 'Rotherham', 'Cornwall', 'Central Bedfordshire', 'North Lincolnshire', 'Oldham', 'Sheffield', 'Suffolk Coastal', 'Southampton', 'Southend-on-Sea', 'St. Helens', 'Tendring', 'Thurrock', 'Stevenage', 'Bedford', 'Stockport', 'Stoke on Trent', 'Horsham', 'Sunderland', 'Swansea', 'Swindon', 'Telford and Wrekin', 'Tower Hamlets', 'Walsall', 'Warrington', 'North Norfolk', 'East Cambridgeshire', 'Halton', 'Wigan', 'Wolverhampton', 'Worthing', 'Lancaster', 'Wrexham', 'Teignbridge', 'York']\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Glasgow'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacadc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Glasgow Centre  in  2015\n",
      "Could not download data from  2015  for  Glasgow Centre\n",
      "Downloading data file for  Glasgow Centre  in  2016\n",
      "Could not download data from  2016  for  Glasgow Centre\n",
      "No data could be downloaded for  Glasgow Centre\n",
      "Downloading data file for  Glasgow City Chambers  in  2015\n",
      "Could not download data from  2015  for  Glasgow City Chambers\n",
      "Downloading data file for  Glasgow City Chambers  in  2016\n",
      "Could not download data from  2016  for  Glasgow City Chambers\n",
      "No data could be downloaded for  Glasgow City Chambers\n",
      "Downloading data file for  Glasgow Great Western Road  in  2015\n",
      "100% [........................................................] 213014 / 213014Downloading data file for  Glasgow Great Western Road  in  2016\n",
      "100% [........................................................] 208118 / 208118Could not create Ox entry for  GGWR\n",
      "Creating .csv file for  Glasgow Great Western Road\n",
      "Downloading data file for  Glasgow High Street  in  2015\n",
      "100% [........................................................] 437909 / 437909Downloading data file for  Glasgow High Street  in  2016\n",
      "100% [........................................................] 491208 / 491208Could not create Ox entry for  GHSR\n",
      "Creating .csv file for  Glasgow High Street\n",
      "Downloading data file for  Glasgow Hope St  in  2015\n",
      "Could not download data from  2015  for  Glasgow Hope St\n",
      "Downloading data file for  Glasgow Hope St  in  2016\n",
      "Could not download data from  2016  for  Glasgow Hope St\n",
      "No data could be downloaded for  Glasgow Hope St\n",
      "Downloading data file for  Glasgow Kerbside  in  2015\n",
      "100% [........................................................] 218988 / 218988Downloading data file for  Glasgow Kerbside  in  2016\n",
      "100% [........................................................] 219981 / 219981Could not create Ox entry for  GLA4\n",
      "Creating .csv file for  Glasgow Kerbside\n",
      "Downloading data file for  Glasgow Townhead  in  2015\n",
      "100% [........................................................] 582060 / 582060Downloading data file for  Glasgow Townhead  in  2016\n",
      "100% [........................................................] 590075 / 590075Creating .csv file for  Glasgow Townhead\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],list_authorities=['Glasgow City'],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d757db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Aberdeen  in  2015\n",
      "100% [........................................................] 585418 / 585418Downloading data file for  Aberdeen  in  2016\n",
      "100% [........................................................] 584495 / 584495Creating .csv file for  Aberdeen\n",
      "Downloading data file for  Aberdeen Erroll Park  in  2015\n",
      "Could not download data from  2015  for  Aberdeen Erroll Park\n",
      "Downloading data file for  Aberdeen Erroll Park  in  2016\n",
      "Could not download data from  2016  for  Aberdeen Erroll Park\n",
      "No data could be downloaded for  Aberdeen Erroll Park\n",
      "Downloading data file for  Aberdeen Union Street Roadside  in  2015\n",
      "100% [........................................................] 218013 / 218013Downloading data file for  Aberdeen Union Street Roadside  in  2016\n",
      "100% [........................................................] 212952 / 212952Could not create Ox entry for  ABD7\n",
      "Creating .csv file for  Aberdeen Union Street Roadside\n",
      "Downloading data file for  Aberdeen Wellington Road  in  2015\n",
      "Could not download data from  2015  for  Aberdeen Wellington Road\n",
      "Downloading data file for  Aberdeen Wellington Road  in  2016\n",
      "100% [........................................................] 194601 / 194601Could not create Ox entry for  ABD8\n",
      "Creating .csv file for  Aberdeen Wellington Road\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Armagh Roadside  in  2015\n",
      "100% [........................................................] 252255 / 252255Downloading data file for  Armagh Roadside  in  2016\n",
      "100% [........................................................] 329828 / 329828Could not create Ox entry for  ARM6\n",
      "Creating .csv file for  Armagh Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Aston Hill  in  2015\n",
      "100% [........................................................] 291896 / 291896Downloading data file for  Aston Hill  in  2016\n",
      "100% [........................................................] 293203 / 293203Creating .csv file for  Aston Hill\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Auchencorth Moss  in  2015\n",
      "100% [........................................................] 515828 / 515828Downloading data file for  Auchencorth Moss  in  2016\n",
      "100% [........................................................] 687514 / 687514Could not create Ox entry for  ACTH\n",
      "Could not create NOx entry for  ACTH\n",
      "Creating .csv file for  Auchencorth Moss\n",
      "Downloading data file for  Bush Estate  in  2015\n",
      "100% [........................................................] 299677 / 299677Downloading data file for  Bush Estate  in  2016\n",
      "100% [........................................................] 305206 / 305206Creating .csv file for  Bush Estate\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Ballymena Antrim Road  in  2015\n",
      "Could not download data from  2015  for  Ballymena Antrim Road\n",
      "Downloading data file for  Ballymena Antrim Road  in  2016\n",
      "Could not download data from  2016  for  Ballymena Antrim Road\n",
      "No data could be downloaded for  Ballymena Antrim Road\n",
      "Downloading data file for  Ballymena Ballykeel  in  2015\n",
      "100% [........................................................] 263188 / 263188Downloading data file for  Ballymena Ballykeel  in  2016\n",
      "100% [........................................................] 346449 / 346449Could not create Ox entry for  BALM\n",
      "Creating .csv file for  Ballymena Ballykeel\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Barnsley  in  2015\n",
      "Could not download data from  2015  for  Barnsley\n",
      "Downloading data file for  Barnsley  in  2016\n",
      "Could not download data from  2016  for  Barnsley\n",
      "No data could be downloaded for  Barnsley\n",
      "Downloading data file for  Barnsley 12  in  2015\n",
      "Could not download data from  2015  for  Barnsley 12\n",
      "Downloading data file for  Barnsley 12  in  2016\n",
      "Could not download data from  2016  for  Barnsley 12\n",
      "No data could be downloaded for  Barnsley 12\n",
      "Downloading data file for  Barnsley Gawber  in  2015\n",
      "100% [........................................................] 497639 / 497639Downloading data file for  Barnsley Gawber  in  2016\n",
      "100% [........................................................] 505746 / 505746Creating .csv file for  Barnsley Gawber\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Barnstaple A39  in  2015\n",
      "100% [........................................................] 341621 / 341621Downloading data file for  Barnstaple A39  in  2016\n",
      "100% [........................................................] 349923 / 349923Could not create Ox entry for  BPLE\n",
      "Could not create NOx entry for  BPLE\n",
      "Creating .csv file for  Barnstaple A39\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Bath A4 Roadside  in  2015\n",
      "Could not download data from  2015  for  Bath A4 Roadside\n",
      "Downloading data file for  Bath A4 Roadside  in  2016\n",
      "Could not download data from  2016  for  Bath A4 Roadside\n",
      "No data could be downloaded for  Bath A4 Roadside\n",
      "Downloading data file for  Bath Roadside  in  2015\n",
      "100% [........................................................] 217200 / 217200Downloading data file for  Bath Roadside  in  2016\n",
      "100% [........................................................] 213328 / 213328Could not create Ox entry for  BATH\n",
      "Creating .csv file for  Bath Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Belfast Centre  in  2015\n",
      "100% [........................................................] 838414 / 838414Downloading data file for  Belfast Centre  in  2016\n",
      "100% [........................................................] 854053 / 854053Creating .csv file for  Belfast Centre\n",
      "Downloading data file for  Belfast Clara St  in  2015\n",
      "Could not download data from  2015  for  Belfast Clara St\n",
      "Downloading data file for  Belfast Clara St  in  2016\n",
      "Could not download data from  2016  for  Belfast Clara St\n",
      "No data could be downloaded for  Belfast Clara St\n",
      "Downloading data file for  Belfast East  in  2015\n",
      "Could not download data from  2015  for  Belfast East\n",
      "Downloading data file for  Belfast East  in  2016\n",
      "Could not download data from  2016  for  Belfast East\n",
      "No data could be downloaded for  Belfast East\n",
      "Downloading data file for  Belfast South  in  2015\n",
      "Could not download data from  2015  for  Belfast South\n",
      "Downloading data file for  Belfast South  in  2016\n",
      "Could not download data from  2016  for  Belfast South\n",
      "No data could be downloaded for  Belfast South\n",
      "Downloading data file for  Belfast Stockman's Lane  in  2015\n",
      "100% [........................................................] 292194 / 292194Downloading data file for  Belfast Stockman's Lane  in  2016\n",
      "100% [........................................................] 292667 / 292667Could not create Ox entry for  BEL1\n",
      "Creating .csv file for  Belfast Stockman's Lane\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Billingham  in  2015\n",
      "100% [........................................................] 207003 / 207003Downloading data file for  Billingham  in  2016\n",
      "100% [........................................................] 206509 / 206509Could not create Ox entry for  BIL\n",
      "Creating .csv file for  Billingham\n",
      "Downloading data file for  Stockton-on-Tees A1305 Roadside  in  2015\n",
      "100% [........................................................] 142913 / 142913Downloading data file for  Stockton-on-Tees A1305 Roadside  in  2016\n",
      "100% [........................................................] 349061 / 349061Could not create Ox entry for  SOTR\n",
      "Creating .csv file for  Stockton-on-Tees A1305 Roadside\n",
      "Downloading data file for  Stockton-on-Tees Eaglescliffe  in  2015\n",
      "100% [........................................................] 319136 / 319136Downloading data file for  Stockton-on-Tees Eaglescliffe  in  2016\n",
      "100% [........................................................] 307345 / 307345Could not create Ox entry for  EAGL\n",
      "Creating .csv file for  Stockton-on-Tees Eaglescliffe\n",
      "Downloading data file for  Stockton-on-Tees Yarm  in  2015\n",
      "Could not download data from  2015  for  Stockton-on-Tees Yarm\n",
      "Downloading data file for  Stockton-on-Tees Yarm  in  2016\n",
      "Could not download data from  2016  for  Stockton-on-Tees Yarm\n",
      "No data could be downloaded for  Stockton-on-Tees Yarm\n",
      "Metadata file already exists, skipping download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid end year, out of range for  Bassetlaw\n",
      "Invalid end year. The latest you can select for  Bassetlaw  is  1991\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birkenhead Borough Road  in  2015\n",
      "Could not download data from  2015  for  Birkenhead Borough Road\n",
      "Downloading data file for  Birkenhead Borough Road  in  2016\n",
      "100% [..........................................................] 65127 / 65127Could not create Ox entry for  BBRD\n",
      "Creating .csv file for  Birkenhead Borough Road\n",
      "Downloading data file for  Wirral Tranmere  in  2015\n",
      "100% [........................................................] 445831 / 445831Downloading data file for  Wirral Tranmere  in  2016\n",
      "100% [........................................................] 460800 / 460800Creating .csv file for  Wirral Tranmere\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Birmingham A4540 Roadside  in  2015\n",
      "Could not download data from  2015  for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham A4540 Roadside  in  2016\n",
      "Creating .csv file for  Birmingham A4540 Roadside\n",
      "Data file already exists Birmingham Acocks Green  in  2015\n",
      "Data file already exists Birmingham Acocks Green  in  2016\n",
      "Creating .csv file for  Birmingham Acocks Green\n",
      "Downloading data file for  Birmingham Centre  in  2015\n",
      "Could not download data from  2015  for  Birmingham Centre\n",
      "Downloading data file for  Birmingham Centre  in  2016\n",
      "Could not download data from  2016  for  Birmingham Centre\n",
      "No data could be downloaded for  Birmingham Centre\n",
      "Downloading data file for  Birmingham East  in  2015\n",
      "Could not download data from  2015  for  Birmingham East\n",
      "Downloading data file for  Birmingham East  in  2016\n",
      "Could not download data from  2016  for  Birmingham East\n",
      "No data could be downloaded for  Birmingham East\n",
      "Downloading data file for  Birmingham Ladywood  in  2015\n",
      "Could not download data from  2015  for  Birmingham Ladywood\n",
      "Downloading data file for  Birmingham Ladywood  in  2016\n",
      "Could not download data from  2016  for  Birmingham Ladywood\n",
      "No data could be downloaded for  Birmingham Ladywood\n",
      "Data file already exists Birmingham Tyburn  in  2015\n",
      "Data file already exists Birmingham Tyburn  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2015\n",
      "Data file already exists Birmingham Tyburn Roadside  in  2016\n",
      "Creating .csv file for  Birmingham Tyburn Roadside\n",
      "Metadata file already exists, skipping download.\n",
      "Invalid end year, out of range for  Bromsgrove\n",
      "Invalid end year. The latest you can select for  Bromsgrove  is  1978\n",
      "Metadata file already exists, skipping download.\n",
      "Downloading data file for  Blackburn Accrington Road  in  2015\n",
      "100% [........................................................] 201802 / 201802Downloading data file for  Blackburn Accrington Road  in  2016\n"
     ]
    }
   ],
   "source": [
    "gd.UK_AURN_download([2015,2016],path='./normet/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb77b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
